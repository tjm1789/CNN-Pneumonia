{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d551f3dd",
   "metadata": {},
   "source": [
    "# Pneumonia CNN Baseline\n",
    "Clean multiâ€‘cell notebook version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cc5cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "DATA_DIR = \"chest_xray\"   # <-- CHANGE THIS\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dir = os.path.join(DATA_DIR, \"train\")\n",
    "val_dir   = os.path.join(DATA_DIR, \"val\")\n",
    "test_dir  = os.path.join(DATA_DIR, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5821406d",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c35ad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    val_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a8530d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.prefetch(AUTOTUNE)\n",
    "val_ds   = val_ds.prefetch(AUTOTUNE)\n",
    "test_ds  = test_ds.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36814c3",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826fde3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip('horizontal'),\n",
    "    layers.RandomRotation(0.05),\n",
    "    layers.RandomZoom(0.1),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513b56a7",
   "metadata": {},
   "source": [
    "## Build CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a04b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_model(\n",
    "    input_shape=IMG_SIZE + (3,),\n",
    "    num_filters=(32, 64, 128),\n",
    "    dense_units=128,\n",
    "    dropout_rate=0.5,\n",
    "):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    x = data_augmentation(inputs)\n",
    "    x = layers.Rescaling(1.0/255)(x)\n",
    "\n",
    "    for f in num_filters:\n",
    "        x = layers.Conv2D(f, 3, padding='same', activation='relu')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.MaxPooling2D()(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(dense_units, activation='relu')(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(1e-4),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', keras.metrics.AUC(), keras.metrics.Precision(), keras.metrics.Recall()]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = build_cnn_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a90711",
   "metadata": {},
   "source": [
    "## Class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfae75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_count = 1341\n",
    "pneu_count = 3875\n",
    "total = normal_count + pneu_count\n",
    "\n",
    "class_weight = {\n",
    "    0: total / (2 * normal_count),\n",
    "    1: total / (2 * pneu_count),\n",
    "}\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02abc7fd",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9365db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
    "    keras.callbacks.ModelCheckpoint('best_pneumonia_cnn.keras', save_best_only=True),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc2e2ac",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485e585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    class_weight=class_weight,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dde185",
   "metadata": {},
   "source": [
    "## Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed97ba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = model.evaluate(test_ds)\n",
    "list(zip(model.metrics_names, test_metrics))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
