{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d551f3dd",
   "metadata": {},
   "source": [
    "# Pneumonia CNN Baseline\n",
    "Clean multi‑cell notebook version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cc5cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "DATA_DIR = \"chest_xray\"\n",
    "IMG_SIZE = (160, 160)\n",
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dir = os.path.join(DATA_DIR, \"train\")\n",
    "val_dir   = os.path.join(DATA_DIR, \"val\")\n",
    "test_dir  = os.path.join(DATA_DIR, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c561a236",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5821406d",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c35ad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    val_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a8530d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.prefetch(AUTOTUNE)\n",
    "val_ds   = val_ds.prefetch(AUTOTUNE)\n",
    "test_ds  = test_ds.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36814c3",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826fde3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip('horizontal'),\n",
    "    layers.RandomRotation(0.05),\n",
    "    layers.RandomZoom(0.1),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513b56a7",
   "metadata": {},
   "source": [
    "## Build CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a04b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_model(\n",
    "    input_shape=IMG_SIZE + (3,),\n",
    "    num_filters=(16, 32, 64),\n",
    "    dense_units=64,\n",
    "    dropout_rate=0.5,\n",
    "):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    x = data_augmentation(inputs)\n",
    "    x = layers.Rescaling(1.0/255)(x)\n",
    "\n",
    "    for f in num_filters:\n",
    "        x = layers.Conv2D(f, 3, padding='same', activation='relu')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.MaxPooling2D()(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(dense_units, activation='relu')(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(1e-4),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', keras.metrics.AUC(), keras.metrics.Precision(), keras.metrics.Recall()]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = build_cnn_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a90711",
   "metadata": {},
   "source": [
    "## Class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfae75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_count = 1341\n",
    "pneu_count = 3875\n",
    "total = normal_count + pneu_count\n",
    "\n",
    "class_weight = {\n",
    "    0: total / (2 * normal_count),\n",
    "    1: total / (2 * pneu_count),\n",
    "}\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02abc7fd",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9365db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
    "    keras.callbacks.ModelCheckpoint('best_pneumonia_cnn.keras', save_best_only=True),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc2e2ac",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485e585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    class_weight=class_weight,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dde185",
   "metadata": {},
   "source": [
    "## Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed97ba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = model.evaluate(test_ds)\n",
    "list(zip(model.metrics_names, test_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d788cd30",
   "metadata": {},
   "source": [
    "Quick test: comparing different CNN depths\n",
    "\n",
    "This section runs a small comparison to see how the number of conv–pool blocks affects model performance. All other settings (optimizer, augmentation, dropout, batch size, etc.) are kept the same so that depth is the only variable being changed.\n",
    "\n",
    "The three architectures tested are:\n",
    "\n",
    "1 block: (32,) – very shallow\n",
    "\n",
    "2 blocks: (32, 64) – lightweight baseline\n",
    "\n",
    "3 blocks: (32, 64, 128) – slightly deeper\n",
    "\n",
    "Since the aim is just to compare behaviour rather than fully train each model, the runs are limited to 5 epochs with EarlyStopping enabled. The key things being observed are:\n",
    "\n",
    "differences in validation accuracy and validation loss\n",
    "\n",
    "whether deeper models begin to overfit sooner\n",
    "\n",
    "the change in training time per epoch across depths\n",
    "\n",
    "The depth that performs best here will be used as the recommended architecture for the final combined model later in the project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
